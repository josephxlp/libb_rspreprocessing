{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N09E105 /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif /media/ljp238/12TBWolf/BRCHIEVE/TDEM12VFILL/N09E105/N09E105_TDX12_WGS.tif\n",
      "Processando: /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif -> mlinterps\n",
      "read_dem\n",
      "mask_invalid_values\n",
      "Training new model: catboost\n",
      "interpolate_missing_values\n",
      "No valid data to train the model or no missing values to interpolate.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m fo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtiles_ydpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_TDX12_WGS.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m \u001b[43mdemvfill_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempo total de execução: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mti)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMétodo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Tiles processados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tilenames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 118\u001b[0m, in \u001b[0;36mdemvfill_unsupervised\u001b[0;34m(dem_ipath, dem_opath, method, smoothing_iterations, model_params)\u001b[0m\n\u001b[1;32m    115\u001b[0m func, suffix \u001b[38;5;241m=\u001b[39m method_map[method]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Processa o DEM com os parâmetros fornecidos\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem_ipath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdem_opath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcatboost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinalizado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdem_opath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempo de execução: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mti)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 80\u001b[0m, in \u001b[0;36mmlinterps\u001b[0;34m(dem_ipath, dem_opath, model_type, model_params)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Interpolate missing values\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolate_missing_values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m data, model \u001b[38;5;241m=\u001b[39m interpolate_missing_values_smodel(data, model_type, model, model_params, dem_opath, meta)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dem\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m save_dem(dem_opath, data, meta)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N09E105 /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif /media/ljp238/12TBWolf/BRCHIEVE/TDEM12VFILL/N09E105/N09E105_TDX12_WGS.tif\n",
      "Processando: /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif -> mlinterps\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlinterpe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m fo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtiles_ydpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_TDX12_WGS.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdemvfill_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempo total de execução: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mti)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMétodo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Tiles processados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tilenames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 91\u001b[0m, in \u001b[0;36mdemvfill_unsupervised\u001b[0;34m(dem_ipath, dem_opath, method, smoothing_iterations, model_params)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessando: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdem_ipath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Mapeamento dos métodos para as funções correspondentes\u001b[39;00m\n\u001b[1;32m     89\u001b[0m method_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlinterps\u001b[39m\u001b[38;5;124m'\u001b[39m: (mlinterps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mlinterps.tif\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlinterpe\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[43mmlinterpe\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mlinterpe.tif\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     92\u001b[0m }\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Verifica se o método é válido\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m method_map:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlinterpe' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N09E105'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \n",
    "tilename = string[-2]\n",
    "tilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import rasterio\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib  # For saving and loading models\n",
    "import json    # For saving parameters\n",
    "\n",
    "\n",
    "def get_best_gpu():\n",
    "    \"\"\"Selects the best available GPU based on memory size.\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if not torch.cuda.is_available():\n",
    "            return 'CPU'\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        if num_gpus == 1:\n",
    "            return 'cuda:0'\n",
    "        \n",
    "        best_gpu = max(range(num_gpus), key=lambda i: torch.cuda.get_device_properties(i).total_memory)\n",
    "        return f'cuda:{best_gpu}'\n",
    "    except ImportError:\n",
    "        return 'CPU'\n",
    "\n",
    "\n",
    "def read_dem(dem_path):\n",
    "    \"\"\"Reads a DEM file and returns the data as a NumPy array along with its metadata.\"\"\"\n",
    "    with rasterio.open(dem_path) as src:\n",
    "        data = src.read(1).astype(np.float32)  # Read first band\n",
    "        meta = src.meta\n",
    "    return data, meta\n",
    "\n",
    "\n",
    "def mask_invalid_values(data, nodata_value=-9999, min_valid=-50, max_valid=2000):\n",
    "    \"\"\"Masks out invalid values by setting them to NaN.\"\"\"\n",
    "    print(f\"Masking invalid values: nodata={nodata_value}, min_valid={min_valid}, max_valid={max_valid}\")\n",
    "    data = np.where((data <= min_valid) | (data >= max_valid) | (data == nodata_value), np.nan, data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_dem(dem_path, data, meta):\n",
    "    \"\"\"Saves the processed DEM back to a file.\"\"\"\n",
    "    meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
    "    with rasterio.open(dem_path, 'w', **meta) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "\n",
    "def save_model_and_params(model, model_type, params, dem_opath):\n",
    "    \"\"\"Saves the trained model and its parameters to files.\"\"\"\n",
    "    model_filename = f\"{dem_opath}_{model_type}_model.joblib\"\n",
    "    params_filename = f\"{dem_opath}_{model_type}_params.json\"\n",
    "    \n",
    "    joblib.dump(model, model_filename)\n",
    "    with open(params_filename, 'w') as param_file:\n",
    "        json.dump(params, param_file)\n",
    "    print(f\"Model and parameters saved: {model_filename}, {params_filename}\")\n",
    "\n",
    "\n",
    "def interpolate_missing_values_smodel(data, model_type='catboost', model=None, model_params=None, dem_opath=None, meta=None):\n",
    "    \"\"\"Performs interpolation on missing values in a DEM using CatBoost.\"\"\"\n",
    "    mask = np.isfinite(data)\n",
    "    coords = np.array(np.nonzero(mask)).T\n",
    "    values = data[mask]\n",
    "    missing_coords = np.array(np.nonzero(~mask)).T\n",
    "    \n",
    "    print(f\"Valid data points: {len(values)}, Missing data points: {len(missing_coords)}\")\n",
    "    \n",
    "    if len(values) == 0:\n",
    "        print(\"No valid data points to train the model.\")\n",
    "        return data, None  # Ensure both data and model are returned\n",
    "    if len(missing_coords) == 0:\n",
    "        print(\"No missing data points to interpolate.\")\n",
    "        return data, None  # Ensure both data and model are returned\n",
    "\n",
    "    if model is None:\n",
    "        # Initialize CatBoost model with provided or default parameters\n",
    "        model_params = model_params or {\n",
    "            'iterations': 1000,\n",
    "            'verbose': 200,\n",
    "            'early_stopping_rounds': 500,\n",
    "            'task_type': 'GPU' if 'cuda' in get_best_gpu() else 'CPU',\n",
    "        }\n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(coords, values)\n",
    "    \n",
    "    # Interpolate missing values\n",
    "    data[~mask] = model.predict(missing_coords)\n",
    "\n",
    "    # Save training data and mask as GeoTIFF\n",
    "    if dem_opath and meta:\n",
    "        # Save training data (coordinates used in the model)\n",
    "        training_data_filepath = dem_opath.replace('.tif', '_training_data.tif')\n",
    "        null_mask_filepath = dem_opath.replace('.tif', '_null_mask.tif')\n",
    "\n",
    "        # Create an empty array to store training data\n",
    "        training_data = np.full(data.shape, np.nan, dtype=np.float32)\n",
    "        training_data[tuple(coords.T)] = 1  # Mark training data locations\n",
    "        \n",
    "        # Save the training data as a GeoTIFF\n",
    "        with rasterio.open(training_data_filepath, 'w', **meta) as dst:\n",
    "            dst.write(training_data, 1)\n",
    "\n",
    "        # Create an empty array for the null mask\n",
    "        null_mask = np.full(data.shape, 0, dtype=np.uint8)  # 0 means valid, 1 means missing\n",
    "        null_mask[~mask] = 1  # Mark missing data as 1\n",
    "\n",
    "        # Save the null mask as a GeoTIFF\n",
    "        with rasterio.open(null_mask_filepath, 'w', **meta) as dst:\n",
    "            dst.write(null_mask, 1)\n",
    "\n",
    "        print(f\"Training data and null mask saved as GeoTIFFs: {training_data_filepath}, {null_mask_filepath}\")\n",
    "    \n",
    "    return data, model\n",
    "\n",
    "\n",
    "def mlinterps(dem_ipath, dem_opath, model_type='catboost', model_params=None):\n",
    "    \"\"\"Full pipeline: Read, mask, interpolate, save the DEM, and save the model and parameters.\"\"\"\n",
    "    print('Reading DEM...')\n",
    "    data, meta = read_dem(dem_ipath)\n",
    "    print('Masking invalid values...')\n",
    "    data = mask_invalid_values(data)\n",
    "    \n",
    "    # Load existing model if it exists\n",
    "    model_filename = f\"{dem_opath}_{model_type}_model.joblib\"\n",
    "    params_filename = f\"{dem_opath}_{model_type}_params.json\"\n",
    "    model = None\n",
    "    if os.path.isfile(model_filename):\n",
    "        print(f\"Loading existing model: {model_filename}\")\n",
    "        model = joblib.load(model_filename)\n",
    "    else:\n",
    "        print(f\"Training new model: {model_type}\")\n",
    "    \n",
    "    # Interpolate missing values\n",
    "    print('Interpolating missing values...')\n",
    "    data, model = interpolate_missing_values_smodel(data, model_type, model, model_params, dem_opath, meta)\n",
    "    \n",
    "    print('Saving DEM...')\n",
    "    save_dem(dem_opath, data, meta)\n",
    "    \n",
    "    # Save model and parameters\n",
    "    params = {'model_type': model_type, 'model_params': model_params}\n",
    "    save_model_and_params(model, model_type, params, dem_opath)\n",
    "    print('Pipeline completed.')\n",
    "\n",
    "\n",
    "def demvfill_unsupervised(dem_ipath, dem_opath, method='mlinterps', smoothing_iterations=0, model_params=None):\n",
    "    \"\"\"\n",
    "    Fills gaps in DEMs using interpolation methods.\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "\n",
    "    # Check if the input file exists\n",
    "    if not os.path.isfile(dem_ipath):\n",
    "        print(f\"Input file not found: {dem_ipath}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing: {dem_ipath} -> {method}\")\n",
    "\n",
    "    # Mapping of methods to their corresponding functions\n",
    "    method_map = {\n",
    "        'mlinterps': (mlinterps, '_mlinterps.tif'),\n",
    "    }\n",
    "\n",
    "    # Check if the method is valid\n",
    "    if method not in method_map:\n",
    "        print(f\"Method not available: {method}. Try: mlinterps\")\n",
    "        return\n",
    "\n",
    "    # Get the function and output file suffix based on the chosen method\n",
    "    func, suffix = method_map[method]\n",
    "\n",
    "    # Process the DEM with the given parameters\n",
    "    func(dem_ipath, dem_opath, model_type='catboost', model_params=model_params)\n",
    "\n",
    "    print(f\"Completed: {dem_opath}\")\n",
    "    print(f\"Execution time: {(time.perf_counter() - ti)/60:.2f} min(s)\")\n",
    "\n",
    "\n",
    "# # Main execution block\n",
    "# if __name__ == \"__main__\":\n",
    "#     BRCHIEVE = \"/media/ljp238/12TBWolf/BRCHIEVE\"\n",
    "#     X = 12\n",
    "#     si = 0\n",
    "#     method = 'mlinterps'\n",
    "#     model_params = {\n",
    "#         'iterations': 1000,\n",
    "#         'verbose': 200,\n",
    "#         'early_stopping_rounds': 500,\n",
    "#         'task_type': 'GPU' if 'cuda' in get_best_gpu() else 'CPU',\n",
    "#     }\n",
    "\n",
    "#     tiles_xdpath = f\"{BRCHIEVE}/TILES{X}\"\n",
    "#     outdir = f\"{BRCHIEVE}/TDEM{X}VFILL\"\n",
    "#     os.makedirs(tiles_xdpath, exist_ok=True)\n",
    "#     os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "#     try:\n",
    "#         tilenames = os.listdir(tiles_xdpath)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Directory not found: {tiles_xdpath}\")\n",
    "#         tilenames = []\n",
    "\n",
    "#     tdem_vfiles = glob(f\"{tiles_xdpath}/*/*_tdem_dem__Fw.tif\")\n",
    "#     for i, fi in enumerate(tdem_vfiles):\n",
    "#         ti = time.perf_counter()\n",
    "#         if i > 0: break\n",
    "#         tilename = fi.split('/')[-2]\n",
    "#         tiles_ydpath = os.path.join(outdir, tilename)\n",
    "#         os.makedirs(tiles_ydpath, exist_ok=True)\n",
    "#         fo = f\"{tiles_ydpath}/{tilename}_TDX12_WGS.tif\"\n",
    "#         print(f\"{tilename} {fi} {fo}\")\n",
    "#         demvfill_unsupervised(fi, fo, method, smoothing_iterations=si, model_params=model_params)\n",
    "#         print(f\"Total execution time: {(time.perf_counter() - ti)/60:.2f} min(s)\")\n",
    "#         print(f\"Method: {method} | Tiles processed: {len(tilenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N09E105: /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif -> /media/ljp238/12TBWolf/BRCHIEVE/TDEM12VFILL/N09E105/N09E105_TDX12_WGS.tif\n",
      "Error processing /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif: No finite values found in /media/ljp238/12TBWolf/BRCHIEVE/TILES12/N09E105/N09E105_tdem_dem__Fw.tif. Skipping file.\n",
      "Total execution time: 0.02 min(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import rasterio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "\n",
    "def random_forest_interpolation(data):\n",
    "    \"\"\"\n",
    "    Perform random forest interpolation for missing values in 2D data.\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(data)\n",
    "    if not np.any(mask):  # Check if there are any finite values\n",
    "        raise ValueError(\"Input data contains no finite values for interpolation.\")\n",
    "    \n",
    "    coords = np.array(np.nonzero(mask)).T\n",
    "    values = data[mask]\n",
    "    missing_coords = np.array(np.nonzero(~mask)).T\n",
    "\n",
    "    # Train a Random Forest Regressor\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(coords, values)\n",
    "\n",
    "    # Predict missing values\n",
    "    predicted = model.predict(missing_coords)\n",
    "    data[~mask] = predicted\n",
    "    return data, model, coords\n",
    "\n",
    "def catboost_interpolation(data):\n",
    "    \"\"\"\n",
    "    Perform CatBoost interpolation for missing values in 2D data.\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(data)\n",
    "    if not np.any(mask):  # Check if there are any finite values\n",
    "        raise ValueError(\"Input data contains no finite values for interpolation.\")\n",
    "    \n",
    "    coords = np.array(np.nonzero(mask)).T\n",
    "    values = data[mask]\n",
    "    missing_coords = np.array(np.nonzero(~mask)).T\n",
    "\n",
    "    # Train a CatBoost Regressor\n",
    "    model = CatBoostRegressor(verbose=False)\n",
    "    model.fit(coords, values)\n",
    "\n",
    "    # Predict missing values\n",
    "    predicted = model.predict(missing_coords)\n",
    "    data[~mask] = predicted\n",
    "    return data, model, coords\n",
    "\n",
    "def process_tdem_file(input_file, output_file, params):\n",
    "    \"\"\"\n",
    "    Process a single DEM file, perform interpolation, and save the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with rasterio.open(input_file) as src:\n",
    "            dem_data = src.read(1, masked=True)  # Read the first band as a NumPy array\n",
    "            dem_data[dem_data < -30] = np.nan \n",
    "            dem_data[dem_data > 100] = np.nan \n",
    "            profile = src.profile  # Save metadata for writing output\n",
    "\n",
    "        # Check if there are any finite values in the data\n",
    "        if not np.any(np.isfinite(dem_data)):\n",
    "            raise ValueError(f\"No finite values found in {input_file}. Skipping file.\")\n",
    "\n",
    "        # Extract parameters\n",
    "        method = params[\"method\"]\n",
    "        smoothing_iterations = params[\"smoothing_iterations\"]\n",
    "        model_params = params.get(\"model_params\", {})\n",
    "\n",
    "        # Perform interpolation based on the specified method\n",
    "        if method == \"random_forest\":\n",
    "            interpolated_data, model, coords = random_forest_interpolation(dem_data)\n",
    "        elif method == \"catboost\":\n",
    "            interpolated_data, model, coords = catboost_interpolation(dem_data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported interpolation method: {method}\")\n",
    "\n",
    "        # Apply smoothing iterations (placeholder logic)\n",
    "        for _ in range(smoothing_iterations):\n",
    "            interpolated_data = smooth_data(interpolated_data)\n",
    "\n",
    "        # Save the interpolated data to a new file\n",
    "        profile.update(dtype=rasterio.float32)\n",
    "        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(interpolated_data.astype(rasterio.float32), 1)\n",
    "\n",
    "        # Save the mask as a GeoTIFF\n",
    "        mask = np.isfinite(dem_data).astype(np.uint8)\n",
    "        mask_profile = profile.copy()\n",
    "        mask_profile.update(dtype=rasterio.uint8, count=1)\n",
    "        mask_file = os.path.splitext(output_file)[0] + \"_mask.tif\"\n",
    "        with rasterio.open(mask_file, 'w', **mask_profile) as dst:\n",
    "            dst.write(mask, 1)\n",
    "\n",
    "        # Save the model as a pickle file\n",
    "        model_file = os.path.splitext(output_file)[0] + f\"_{method}_model.pkl\"\n",
    "        with open(model_file, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        # Save the training coordinates as a .npy file\n",
    "        coords_file = os.path.splitext(output_file)[0] + \"_training_coords.npy\"\n",
    "        np.save(coords_file, coords)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_file}: {e}\")\n",
    "\n",
    "def smooth_data(data):\n",
    "    \"\"\"\n",
    "    Placeholder function for smoothing data.\n",
    "    Replace with actual smoothing logic if needed.\n",
    "    \"\"\"\n",
    "    return data  # No smoothing applied in this placeholder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BRCHIEVE = \"/media/ljp238/12TBWolf/BRCHIEVE\"\n",
    "    X = 12\n",
    "    si = 0\n",
    "    method = 'mlinterps'\n",
    "    model_params = {\n",
    "        'iterations': 1000,\n",
    "        'verbose': 200,\n",
    "        'early_stopping_rounds': 500,\n",
    "        'task_type': 'GPU' if 'cuda' in get_best_gpu() else 'CPU',\n",
    "    }\n",
    "\n",
    "    tiles_xdpath = f\"{BRCHIEVE}/TILES{X}\"\n",
    "    outdir = f\"{BRCHIEVE}/TDEM{X}VFILL\"\n",
    "    os.makedirs(tiles_xdpath, exist_ok=True)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    tdem_vfiles = glob(f\"{tiles_xdpath}/*/*_tdem_dem__Fw.tif\")\n",
    "\n",
    "    # Define parameters\n",
    "    params = {\n",
    "        \"method\": \"catboost\",  # Choose between \"random_forest\" and \"catboost\"\n",
    "        \"smoothing_iterations\": 1,\n",
    "        \"model_params\": model_params  # Add model-specific parameters here if needed\n",
    "    }\n",
    "\n",
    "    for i, fi in enumerate(tdem_vfiles):\n",
    "        ti = time.perf_counter()\n",
    "\n",
    "        # Process only the first file for demonstration purposes\n",
    "        if i > 0:\n",
    "            break\n",
    "\n",
    "        tilename = fi.split('/')[-2]\n",
    "        tiles_ydpath = os.path.join(outdir, tilename)\n",
    "        os.makedirs(tiles_ydpath, exist_ok=True)\n",
    "        fo = f\"{tiles_ydpath}/{tilename}_TDX12_WGS.tif\"\n",
    "\n",
    "        print(f\"Processing {tilename}: {fi} -> {fo}\")\n",
    "        process_tdem_file(fi, fo, params)\n",
    "        print(f\"Total execution time: {(time.perf_counter() - ti)/60:.2f} min(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
